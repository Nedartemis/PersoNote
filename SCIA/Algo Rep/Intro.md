
Notation : TP à envoyer par mail

CPU ~= 16 cores
GPU ~= 10k cores

CPU reste plus efficace sur des tâches séquentielles.

Data parallelism : dupliquer le modèle et s’entraîner sur des données différentes

Model Parallelism : le modèle est trop grand pour tenir sur un gpu et on pas le séparer
